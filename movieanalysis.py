# -*- coding: utf-8 -*-
"""movieAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EE-yvIkPrqCRBOZUoDe3OpDzsTTKiCWe
"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import pandas as pd

# Load the fine-tuned model and tokenizer

tokenizer = AutoTokenizer.from_pretrained("microsoft/tapex-large-finetuned-wtq")

model = AutoModelForSeq2SeqLM.from_pretrained("microsoft/tapex-large-finetuned-wtq")

data = {
    "Actor": [
        "Brad Pitt",
        "Leonardo DiCaprio",
        "George Clooney",
        "Tom Hanks",
        "Morgan Freeman",
        "Robert De Niro",
        "Al Pacino",
        "Denzel Washington",
        "Tom Cruise",
        "Johnny Depp"
    ],
    "Number_of_Movies": [87, 53, 69, 89, 132, 119, 62, 57, 45, 71],
    "Total_Box_Office_Billions": [7.2, 8.4, 3.5, 9.8, 5.2, 4.8, 3.9, 4.2, 10.1, 8.5],
    "Awards_Won": [2, 1, 2, 2, 1, 2, 1, 2, 0, 1],
    "Highest_Grossing_Movie": [
        "World War Z",
        "Titanic",
        "Ocean's Eleven",
        "Forrest Gump",
        "Dark Knight",
        "Joker",
        "The Godfather",
        "American Gangster",
        "Top Gun: Maverick",
        "Pirates of the Caribbean"
    ],
    "Career_Start_Year": [1987, 1991, 1978, 1980, 1964, 1963, 1969, 1977, 1981, 1984],
    "Average_Movie_Rating": [7.3, 7.5, 6.9, 7.8, 7.4, 7.6, 7.7, 7.2, 7.0, 6.8]
}

table = pd.DataFrame.from_dict(data)


questions = [
    "Who has appeared in the most movies?",
    "What is the average number of movies per actor?",
    "Which actor has the highest total box office earnings?",
    "Who started their career the earliest?",
    "How many actors have won more than 1 award?",
    "What is the average movie rating for Leonardo DiCaprio?",
    "Who has the highest average movie rating?",
    "Which actor started their career after 1985?",
    "What is Tom Cruise's highest grossing movie?",
    "How many actors have appeared in more than 70 movies?"
]

# Iterate through the questions
predicted_answers = []
for question in questions:
    # Encode the table and question
    table_str = table.astype(str)
    encoding = tokenizer(table=table_str, query=question, return_tensors="pt", truncation=True, max_length=512)

    # Generate the answer
    outputs = model.generate(**encoding)

    # Decode the answer
    predicted_answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]
    predicted_answers.append(predicted_answer)

# Print all predicted answers
for q, a in zip(questions, predicted_answers):
    print(f"Q: {q}")
    print(f"A: {a}\n")